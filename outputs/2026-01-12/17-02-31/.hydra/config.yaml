seed: 42
device: cuda
output_dir: ${hydra:runtime.output_dir}
num_clients: ???
federated_rounds: ???
batch_size: ???
subset_size: ???
experiment:
  subset_size: 200
  batch_size: 4
  edge_model_quantization: 4bit
  num_clients: 5
  federated_rounds: 5
data:
  dataset_name: truthfulqa_mc
  split: validation
  metric: accuracy
model:
  edge_model_name: microsoft/Phi-3-mini-4k-instruct
  cloud_model_name: meta-llama/Meta-Llama-3-8B-Instruct
  edge_quantization: 4bit
  max_new_tokens: 256
  temperature: 0.7
federated:
  learning_rate: 2.0e-05
  local_epochs: 1
  communication_cost_tracking: true
